@article{1Bleier_2025,
  abstract={Server-based computing in space has been recently proposed due to potential benefits in terms of capability, latency, security, sustainability, and cost. Despite this, there has been no work asking the ques- tion: how should we architect systems for server-based computing in space when considering overall cost. This paper presents a Total Cost of Ownership (TCO)-based approach to architecture of server-based computing systems for space (Space Microdatacenters - SŒºDC) for processing data produced by low Earth orbit (LEO)-based Earth observation (EO) satellites. We show that power of compute is the primary factor in determin ing SŒºDC TCO, though the dependence is sublinear. Second, the impact of compute mass, monetary cost, and communication on TCO is relatively insignificant. Third, architectures with the highest FLOPs/W provide much higher performance per TCO $ even if they have poor FLOPs/ $ . We leverage these insights to advocate extreme heterogeneity designs for SŒºDCs. These designs reduce SŒºDC TCO by 116√ó in spite of poor FLOPs $ characteristics. We also show that (a) collaborative compute constellations ‚Äî constellations in which EO satellites are also equipped with compute hardware ‚Äî further improve SŒºDC TCO by 1.31 to 1.74√ó, (b) a distributed architecture reduces TCO by 10% over a monolithic architecture, and (c) low monetary cost of compute can be leveraged to provide near zero cost compute overprovisioning which improves an SŒºDC‚Äôs availability significantly and supports graceful degradation. Overall, this is the first paper on cost-aware architecture and optimization of a SŒºDC.},
  title={Architecting Space Microdatacenters: A System-level Approach}, conference={IEEE HPCA},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Bleier, Nathaniel and Eason, Rick and Lembeck, Michael and Kumar, Rakesh}, year={2025}, month=mar}
,
@article{2Bleier_2024,
  abstract={While smell is arguably the most visceral of senses, olfactory computing has been barely explored in the mainstream. We argue that this is a good time to explore olfactory computing since a) a large number of driver applications are emerging, b) odor sensors are now dramatically better, and c) non-traditional form factors such as sensor, wearable, and xR devices that would be required to support olfactory computing are already getting widespread acceptance. Through a comprehensive review of literature, we identify the key algorithms needed to support a wide variety of olfactory computing tasks. We profiled these algorithms on existing hardware and identified several characteristics, including the preponderance of fixed-point computation, and linear operations, and real arithmetic; a variety of data memory requirements; and opportunities for data-level parallelism. We propose Ahromaa, a heterogeneous architecture for olfactory computing targeting extremely power and energy constrained olfactory computing workloads and evaluate it against baseline architectures of an MCU, a state-of-art CGRA, and an MCU with packed SIMD. Across our algorithms, Ahromaa's operating modes outperform the baseline architectures by 1.36, 1.22, and 1.1√ó in energy efficiency when operating at MEOP. We also show how careful design of data memory organization can lead to significant energy savings in olfactory computing, due to the limited amount of data memory many olfactory computing kernels require. These improvements to the data memory organization lead to additional 4.21, 4.37, and 2.85√ó improvements in energy efficiency on average. },
  title={Programmable Olfactory Computing (IEEE Micro Top Picks)}, volume={44}, ISSN={1937-4143}, url={http://dx.doi.org/10.1109/MM.2024.3409619}, DOI={10.1109/mm.2024.3409619}, number={4}, conference={IEEE Micro},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)}, author={Bleier, Nathaniel and Wezelis, Abigail and Varshney, Lav and Kumar, Rakesh}, year={2024}, month=jul, pages={88‚Äì96} }
,
@inproceedings{3Bleier_2023,
  abstract={While smell is arguably the most visceral of senses, olfactory computing has been barely explored in the mainstream. We argue that this is a good time to explore olfactory computing since a) a large number of driver applications are emerging, b) odor sensors are now dramatically better, and c) non-traditional form factors such as sensor, wearable, and xR devices that would be required to support olfactory computing are already getting widespread acceptance. Through a comprehensive review of literature, we identify the key algorithms needed to support a wide variety of olfactory computing tasks. We profiled these algorithms on existing hardware and identified several characteristics, including the preponderance of fixed-point computation, and linear operations, and real arithmetic; a variety of data memory requirements; and opportunities for data-level parallelism. We propose Ahromaa, a heterogeneous architecture for olfactory computing targeting extremely power and energy constrained olfactory computing workloads and evaluate it against baseline architectures of an MCU, a state-of-art CGRA, and an MCU with packed SIMD. Across our algorithms, Ahromaa's operating modes outperform the baseline architectures by 1.36, 1.22, and 1.1√ó in energy efficiency when operating at MEOP. We also show how careful design of data memory organization can lead to significant energy savings in olfactory computing, due to the limited amount of data memory many olfactory computing kernels require. These improvements to the data memory organization lead to additional 4.21, 4.37, and 2.85√ó improvements in energy efficiency on average. },
  doi = {10.1145/3579371.3589061},	url = {https://doi.org/10.1145%2F3579371.3589061},	year = 2023,	month = {jun},	publisher = {{ACM}},	author = {Nathaniel Bleier and Abigail Wezelis and Lav Varshney and Rakesh Kumar},	title = {Programmable Olfactory Computing},	conference = {Proceedings of the 50th Annual International Symposium on Computer Architecture}},
@inproceedings{4Bleier_2023,
  abstract={Many emerging flexible electronics applications require hardware-based encryption, but it is unclear if practical hardware-based encryption is possible for flexible applications due to stringent power requirements of these applications and high area and power overheads of flexible technologies relative to silicon CMOS technologies. In this work, we observe that the lifetime of many flexible applications is so small that often one key suffices for the entire lifetime. This means that, instead of generating keys and round keys in hardware, we can generate the round keys offline, and instead store these round keys directly on the engine post fabrication in an on-chip programmable read-only memory. This eliminates the need for hardware for dynamic generation of round keys, which significantly reduces encryption overhead, while still allowing engines to have unique keys. This significant reduction in encryption overhead allows us to demonstrate the first practical flexible encryption engines. To prevent an adversary from reading out the stored round keys, we scramble the round keys before storing them in the ROM; camouflage cells are used to unscramble the keys before feeding them to logic. In spite of the unscrambling overhead, our encryption engines consume 27.4% lower power than the already heavily area and power-optimized baselines, while being 21.9% smaller on average.}
  doi = {10.23919/date56975.2023.10137258},	url = {https://doi.org/10.23919%2Fdate56975.2023.10137258},	year = 2023,	month = {apr},	publisher = {{IEEE}},	author = {Nathaniel Bleier and M. Husnain Mubarik and Suman Balaji and Francisco Rodriguez and Antony Sou and Scott White and Rakesh Kumar},	title = {Exploiting Short Application Lifetimes for Low Cost Hardware Encryption in Flexible Electronics},	conference = {2023 Design, Automation {\&}amp$\mathsemicolon$ Test in Europe Conference {\&}amp$\mathsemicolon$ Exhibition ({DATE})}},
@article{5Bleier2023,
  abstract={Earth observation (EO) has been a key task for satellites since the first time a satellite was put into space. The temporal and spatial resolution at which EO satellites take pictures has been increasing to support space-based applications, but this increases the amount of data each satellite generates. We observe that future EO satellites will generate so much data that this data cannot be transmitted to Earth due to the limited capacity of communication that exists be- tween space and Earth. We show that conventional data reduction techniques such as compression and early discard do not solve this problem, nor does a direct enhancement of today‚Äôs RF- based infrastructure for space-Earth communication. We explore an unorthodox solution instead - moving to space the com- putation that would have happened on the ground. This alleviates the need for data transfer to Earth. We analyze ten non-longitudinal RGB and hyperspectral image processing Earth observation appli- cations for their computation and power requirements and discover that these requirements cannot be met by the small satellites that dominate today‚Äôs EO missions. We make a case for space micro- datacenters - large computational satellites whose primary task is to support in-space computation of EO data. We show that one 4KW space microdatacenter can support the computation need of a majority of applications, especially when used in conjunction with early discard. We do find, however, that communication between EO satellites and space microdatacenters becomes a bottleneck. We propose three space microdatacenter-communication co-design strategies ‚Äì ùëò ‚àí ùëôùëñùë†ùë°-based network topology, microdatacenter split- ting, and moving space microdatacenters to geostationary orbit ‚Äì that alleviate the bottlenecks and enable effective usage of space microdatacenters. },
  title = {Space Microdatacenters},
  publisher={IEEE},
  month={nov},
  conference = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO 2023},year = {2023},pages = {900-915},author = {Bleier, N. and Mubarik, M.H. and Swenson, G.R. and Kumar, R.}},
@article{6Bleier2023,
  month={nov},
  publisher={arxiv},
  abstract={Mitigating losses from supply and demand volatility in the semiconductor supply chain and market has traditionally been cast as a logistics and forecasting problem. We investigate how the architecture of a family of chips influences how it is affected by supply and demand uncertainties. We observe that semiconductor supply chains become fragile, in part, due to single demand paths, where one chip can satisfy only one demand. Chip architects can enable multiple paths to satisfy a chip demand, which improves supply chain resilience. Based on this observation, we study composition and adaptation as architectural strategies to improve resilience to volatility and also introduce a third strategy of dispersion. These strategies allow multiple paths to satisfy a given chip demand. We develop a model to analyze the impact of these architectural techniques on supply chain costs under different regimes of uncertainties and evaluate what happens when they are combined. We present several interesting and even counterintuitive observations about the product configurations and market conditions where these interventions are impactful and where they are not. In all, we show that product redesign supported by architectural changes can mitigate nearly half of the losses caused by supply and demand volatility. As far as we know, this is the first such investigation concerning chip architecture.},
  title = {Understanding Interactions Between Chip Architecture and Uncertainties in Semiconductor Supply and Demand},conference = {arXiv},year = {2023},author = {Kanungo, R. and Siva, S. and Bleier, N. and Mubarik, M.H. and Varshney, L. and Kumar, R.}},
@inproceedings{7Bleier_2022,
  abstract={Flexible electronics is a promising approach to target applications whose computational needs are not met by traditional silicon-based electronics due to their conformality, thinness, or cost requirements. A microprocessor is a critical component for many such applications; however, it is unclear whether it is feasible to build flexible processors at scale (i.e., at high yield), since very few flexible microprocessors have been reported and no yield data or data from multiple chips has been reported. Also, prior manufactured flexible systems were not field-reprogrammable and were evaluated either on a simple set of test vectors or a single program. A working flexible microprocessor chip supporting complex or multiple applications has not been demonstrated. Finally, no prior work performs a design space of flexible microprocessors to optimize area, code size, and energy of such microprocessors. In this work, we fabricate and test hundreds of FlexiCores - flexible 0.8 Œºm IGZO TFT-based field-reprogrammable 4 and 8-bit microprocessor chips optimized for low footprint and yield. We show that these gate count-optimized processors can have high yield (4-bit FlexiCores have 81% yield - sufficient to enable sub-cent cost if produced at volume). We evaluate these chips over a suite of representative kernels - the kernels take 4.28 ms to 12.9 ms and 21.0 ŒºJ to 61.4 ŒºJ for execution (at 360 nJ per instruction). We also present the first characterization of process variation for a flexible processor - we observe significant process variation (relative standard deviation of 15.3% and 21.5% in terms of current draw of 4-bit and 8-bit FlexiCore chips respectively). Finally, we perform a design space exploration and identify design points much better than FlexiCores - the new cores consume only 45--56% the energy of the base design, and have code size less than 30% of the base design, with an area overhead of 9-37%.},
  doi = {10.1145/3470496.3527410},	url = {https://doi.org/10.1145%2F3470496.3527410},	year = 2022,	month = {jun},	publisher = {{ACM}},	author = {Nathaniel Bleier and Calvin Lee and Francisco Rodriguez and Antony Sou and Scott White and Rakesh Kumar},	title = {FlexiCores},	conference = {Proceedings of the 49th Annual International Symposium on Computer Architecture}},
@inproceedings{8Bleier_2022,
  abstract={Earables such as earphones, hearing aids, and smart glasses are poised to be a prominent programmable computing platform in the future. In this paper, we ask the question: what kind of programmable hardware would be needed to support earable computing in future? To understand hardware requirements, we propose EarBench, a suite of representative emerging earable applications with diverse sensor-based inputs and computation requirements. Our analysis of EarBench applications shows that, on average, there is a 13.54√ó-3.97√ó performance gap between the computational needs of EarBench applications and the performance of the microprocessors that several of today's programmable earable SoCs are based on; more complex microprocessors have unacceptable energy efficiency for Earable applications. Our analysis also shows that EarBench applications are dominated by a small number of digital signal processing (DSP) and machine learning (ML)-based kernels that have significant computational similarity. We propose SpEaC --- a coarse-grained reconfigurable spatial architecture - as an energy-efficient programmable processor for earable applications. SpEaC targets earable applications efficiently using a) a reconfigurable fixed-point multiply-and-add augmented reduction tree-based substrate with support for vectorized complex operations that is optimized for the earable ML and DSP kernel code and b) a tightly coupled control core for executing other code (including non-matrix computation, or non-multiply or add operations in the earable DSP kernel code). Unlike other CGRAs that typically target general-purpose computations, SpEaC substrate is optimized for energy-efficient execution of the earable kernels at the expense of generality. Across all our kernels, SpEaC outperforms programmable cores modeled after M4, M7, A53, and HiFi4 DSP by 99.3√ó, 32.5√ó, 14.8√ó, and 9.8√ó respectively. At 63 mW in 28 nm, the energy efficiency benefits are 1.55 √ó, 9.04√ó, 68.3 √ó, and 32.7 √ó respectively; energy efficiency benefits are 15.7 √ó -- 1087 √ó over a low power Mali T628 MP6 GPU.},
  doi = {10.1145/3470496.3527396},	url = {https://doi.org/10.1145%2F3470496.3527396},	year = 2022,	month = {jun},	publisher = {{ACM}},	author = {Nathaniel Bleier and Muhammad Husnain Mubarik and Srijan Chakraborty and Shreyas Kishore and Rakesh Kumar},	title = {Rethinking programmable earable processors},	conference = {Proceedings of the 49th Annual International Symposium on Computer Architecture}},
@inproceedings{9Bleier_2021,
  abstract={As the diversity of computing workloads and customers continues to increase, so does the need to customize hardware at low cost for different computing needs. This work focuses on automatic customization of a given hardware, available as a soft or firm IP, through eliminating unneeded or undesired instruction set architecture (ISA) instructions. We present a property-based framework for automatically generating reduced-ISA hardware. Our framework directly operates on a given arbitrary RTL or gate-level netlist, uses property checking to identify gates that are guaranteed to not toggle if only a reduced ISA needs to be supported, and automatically eliminates these untoggleable gates to generate a new design. We show a 14% gate count reduction when the Ibex core is optimized using our framework for the instructions required by a set of embedded (MiBench) workloads. Reduced-ISA versions generated by our framework that support a limited set of ISA extensions and which cannot be generated using Ibex‚Äôs parameterization options provide 10%47% gate count reduction. For an obfuscated Cortex M0 netlist optimized to support the instructions in the MiBench benchmarks, we observe a 20% area reduction and 18% gate count reduction compared to the baseline core, demonstrating applicability of our framework to obfuscated designs. We demonstrate the scalability of our approach by applying our framework to a 100,000-gate RIDECORE design, showing a 14%-17% gate count reduction. },
  doi = {10.1109/dac18074.2021.9586090},	url = {https://doi.org/10.1109%2Fdac18074.2021.9586090},	year = 2021,	month = {dec},	publisher = {{IEEE}},	author = {Nathan Bleier and John Sartori and Rakesh Kumar},	title = {Property-driven Automatic Generation of Reduced-{ISA} Hardware},	conference = {2021 58th {ACM}/{IEEE} Design Automation Conference ({DAC})}},
@inproceedings{Weller_2021,
  abstract={Printed electronics (PE) offers flexible, extremely low-cost, and on-demand hardware due to its additive manufacturing process, enabling emerging ultra-low-cost applications, including machine learning applications. However, large feature sizes in PE limit the complexity of a machine learning classifier (e.g., a neural network (NN)) in PE. Stochastic computing Neural Networks (SC-NNs) can reduce area in silicon technologies, but still require complex designs due to unique implementation tradeoffs in PE. In this paper, we propose a printed mixed-signal system, which substitutes complex and power-hungry conventional stochastic computing (SC) components by printed analog designs. The printed mixed-signal SC consumes only 35% of power consump- tion and requires only 25% of area compared to a conventional 4-bit NN implementation. We also show that the proposed mixed- signal SC-NN provides good accuracy for popular neural network classification problems. We consider this work as an important step towards the realization of printed SC-NN hardware for near- sensor-processing. },
  doi = {10.23919/date51398.2021.9474254},	url = {https://doi.org/10.23919%2Fdate51398.2021.9474254},	year = 2021,	month = {feb},	publisher = {{IEEE}},	author = {Dennis D. Weller and Nathaniel Bleier and Michael Hefenbrock and Jasmin Aghassi-Hagmann and Michael Beigl and Rakesh Kumar and Mehdi B. Tahoori},	title = {Printed Stochastic Computing Neural Networks},	conference = {2021 Design, Automation {\&}amp$\mathsemicolon$ Test in Europe Conference {\&}amp$\mathsemicolon$ Exhibition ({DATE})}},
@inproceedings{Mubarik_2020,
  abstract = {A large number of application domains have requirements on cost, conformity, and non-toxicity that silicon-based computing systems cannot meet, but that may be met by printed electronics. For several of these domains, a typical computational task to be performed is classification. In this work, we explore the hardware cost of inference engines for popular classification algorithms (Multi-Layer Perceptrons, Support Vector Machines (SVMs), Logistic Regression, Random Forests and Binary Decision Trees) in EGT and CNT-TFT printed technologies and determine that Decision Trees and SVMs provide a good balance between accuracy and cost. We evaluate conventional Decision Tree and SVM architectures in these technologies and conclude that their area and power overhead must be reduced. We explore, through SPICE and gate-level hardware simulations and multiple working prototypes, several classifier architectures that exploit the unique cost and implementation tradeoffs in printed technologies - a) Bespoke printed classifers that are customized to a model generated for a given application using specific training datasets, b) Lookup-based printed classifiers where key hardware computations are replaced by lookup tables, and c) Analog printed classifiers where some classifier components are replaced by their analog equivalents. Our evaluations show that bespoke implementation of EGT printed Decision Trees has 48.9√ó lower area (average) and 75.6√ó lower power (average) than their conventional equivalents; corresponding benefits for bespoke SVMs are 12.8√ó and Decision outperform 12.7√ó respectively. Lookup-based Trees their non-lookup bespoke equivalents by 38% and 70%; lookup-based SVMs are better by 8% and 0.6%. Analog printed Decision Trees provide 437√ó area and 27√ó power benefits over digital bespoke counterparts; analog SVMs yield 490√ó area and 12√ó power improvements. Our results and prototypes demonstrate feasibility of fabricating and deploying battery and self-powered printed classifiers in the application domains of interest.},
  doi = {10.1109/micro50266.2020.00019},	url = {https://doi.org/10.1109%2Fmicro50266.2020.00019},	year = 2020,	month = {oct},	publisher = {{IEEE}},	author = {Muhammad Husnain Mubarik and Dennis D. Weller and Nathaniel Bleier and Matthew Tomei and Jasmin Aghassi-Hagmann and Mehdi B. Tahoori and Rakesh Kumar},	title = {Printed Machine Learning Classifiers},	conference = {2020 53rd Annual {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})}},
@inproceedings{10Bleier_2020,
  doi = {10.1109/isca45697.2020.00028},	url = {https://doi.org/10.1109%2Fisca45697.2020.00028},	year = 2020,	month = {may},	publisher = {{IEEE}},	author = {Nathaniel Bleier and Muhammad Husnain Mubarik and Farhan Rasheed and Jasmin Aghassi-Hagmann and Mehdi B Tahoori and Rakesh Kumar},	title = {Printed Microprocessors},
  abstract = {Printed electronics holds the promise of meeting the cost and conformality needs of emerging disposable and ultra-low cost margin applications. Recent printed circuits technologies also have low supply voltage and can, therefore, be battery- powered. In this paper, we explore the design space of micro- processors implemented in such printing technologies - these printed microprocessors will be needed for battery-powered applications with requirements of low cost, conformality, and programmability. To enable this design space exploration, we first present the standard cell libraries for EGFET and CNT-TFT printed technologies - to the best of our knowledge, these are the first synthesis and physical design ready stan- dard cell libraries for any low voltage printing technology. We then present an area, power, and delay characterization of several off-the-shelf low gate count microprocessors (Z80, light8080, ZPU, and openMSP430) in EGFET and CNT-TFT technologies. Our characterization shows that several print- ing applications can be feasibly targeted by battery-powered printed microprocessors. However, our results also show the need to significantly reduce area and power of such printed microprocessors. We perform a design space exploration of printed microprocessor architectures over multiple parame- ters - datawidths, pipeline depth, etc. We show that the best cores outperform pre-existing cores by at least one order of magnitude in terms of power and area. Finally, we show that printing-specific architectural and low-level optimiza- tions further improve area and power characteristics of low voltage battery-compatible printed microprocessors. Program- specific ISA, for example, improves power, and area by up to 4.18x and 1.93x respectively. Crosspoint-based instruction ROM outperforms a RAM-based design by 5.77x, 16.8x, and 2.42x respectively in terms of power, area, and delay.},
  conference = {2020 {ACM}/{IEEE} 47th Annual International Symposium on Computer Architecture ({ISCA})}}
